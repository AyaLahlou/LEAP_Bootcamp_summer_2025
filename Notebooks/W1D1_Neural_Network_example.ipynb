{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db62c8c-c675-4eac-9411-3d17b7f4a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff50ac-0c48-4447-8eb0-974e676a5f47",
   "metadata": {},
   "source": [
    "This notebook shows how to apply Neural Networks to predict the global temperature, based on the time series of CO2 & CH4.\n",
    "\n",
    "By Weiwei Zhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16e964-54e5-4a97-ac3e-5603912caf41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ac29c-3193-4c8e-a19c-659354df31cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = \"gs://leap-persistent/jbusecke/data/climatebench/train_val/\"\n",
    "test_path = \"gs://leap-persistent/jbusecke/data/climatebench/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efe084-8100-4228-9446-2b6b993b17b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some visualization of the ClimateBench data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d097b9-5c23-4112-b696-87908c7a0c05",
   "metadata": {},
   "source": [
    "Before training ML models, let's plot the ClimateBench dataset for quick checking.\n",
    "\n",
    "ClimateBench is a spatial-temporal dataset that contains simulations generated by the NorESM2 model. It provides both historical simulations & future projections under different scenarios (e.g., ssp245).\n",
    "\n",
    "Four future scenarios are plotted here: `ssp126, ssp245, ssp370, ssp585`.\n",
    "\n",
    "\n",
    "1. ssp126 (Low): low population growth, high levels of education, and global cooperation to address environmental and social issues.\n",
    "\n",
    "2. ssp245 (Medium): intermediate challenges to mitigation and adaptation - moderate population growth, intermediate levels of education, and a balanced emphasis on economic development and environmental sustainability.\n",
    "\n",
    "3. ssp370 (High): continued high population growth, limited environmental regulations, and slow technological progress in achieving sustainability goals.\n",
    "\n",
    "4. ssp585 (Very High): high population growth, limited technological innovation in sustainability, and high reliance on fossil fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d731b-012b-4d04-b743-9a85a838a5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios = ['historical','ssp126','ssp370','ssp585']\n",
    "inputs = [os.path.join(train_path , f\"inputs_{scenario}\") for scenario in scenarios]\n",
    "inputs.append(os.path.join(test_path, \"inputs_ssp245\"))\n",
    "inputs.sort(key=lambda x:x.split('_')[-1])\n",
    "\n",
    "outputs = [os.path.join(train_path , f\"outputs_{scenario}\") for scenario in scenarios]\n",
    "outputs.append(os.path.join(test_path, \"outputs_ssp245\"))\n",
    "outputs.sort(key=lambda x:x.split('_')[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c97ea8-e674-433e-ac85-218de0fb4307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "colors  = ['tab:blue','tab:green','tab:purple','tab:orange','tab:red']\n",
    "\n",
    "\n",
    "for i,input in enumerate(inputs):\n",
    "\n",
    "    label=input.split('_')[-1]#[:-3]\n",
    "    X = open_dataset(input)\n",
    "    x = X.time.data\n",
    "    \n",
    "    X['CO2'].plot(label=label,color=colors[i],linewidth=2,ax=axes[0])\n",
    "    # axes[0].plot(x, X['CO2'].data, label=label,color=colors[i],linewidth=2)\n",
    "    axes[0].set_ylabel(\"Cumulative anthropogenic CO2 \\nemissions since 1850 (GtCO2)\")\n",
    "    \n",
    "    X['CH4'].plot(label=label,color=colors[i],linewidth=2,ax=axes[1])\n",
    "    # axes[1].plot(x, X['CH4'].data, label=label,color=colors[i],linewidth=2)\n",
    "    axes[1].set_ylabel(\"Anthropogenic CH4 \\nemissions (GtCH4 / year)\")\n",
    "    \n",
    "axes[0].set_title('CO2')\n",
    "axes[1].set_title('CH4')\n",
    "axes[0].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be23b96-7db1-4ceb-b651-9bc5887b5f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9,4))\n",
    "\n",
    "for i,output in enumerate(outputs):\n",
    "\n",
    "    label=output.split('_')[-1]#[:-3]\n",
    "    X = open_dataset(output).mean(dim=\"member\")[['tas']].drop(['quantile'])\n",
    "    x = X.time.data\n",
    "    \n",
    "    weights  = np.cos(np.deg2rad(X.lat))\n",
    "    tas_mean = X['tas'].weighted(weights).mean(['lat', 'lon']).data\n",
    "    tas_std  = X['tas'].weighted(weights).std(['lat', 'lon']).data\n",
    "    \n",
    "    ax.plot(x, tas_mean, label=label,color=colors[i],linewidth=2)\n",
    "    ax.fill_between(x,tas_mean+tas_std,tas_mean-tas_std,facecolor=colors[i],alpha=0.2)\n",
    "    \n",
    "ax.set_ylabel(\"Global average temperature\\n since 1850 (°C)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fa381-349e-4570-88be-c833d1097d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_his    = open_dataset(os.path.join(train_path , \"outputs_historical\")).mean(dim=\"member\")[['tas']].drop(['quantile'])\n",
    "y_ssp370 = open_dataset(os.path.join(train_path,'outputs_ssp370')).mean(dim=\"member\")[['tas']].drop(['quantile'])\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(figsize=(18,4.5),ncols=3)\n",
    "yr0, yr1, yr2 = 1900, 1950, 2000\n",
    "vmin, vmax = -5, 5\n",
    "\n",
    "y_his.sel(time=yr0).tas.plot(ax=axes.flat[0],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "y_his.sel(time=yr1).tas.plot(ax=axes.flat[1],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "y_his.sel(time=yr2).tas.plot(ax=axes.flat[2],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "\n",
    "fig.suptitle('historical simulations for temperature',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2d104-49e2-48f8-93ed-f44cdafd86f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_ssp370 = open_dataset(os.path.join(train_path,'outputs_ssp370')).mean(dim=\"member\")[['tas']].drop(['quantile'])\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(figsize=(18,4.5),ncols=3)\n",
    "yr0, yr1, yr2 = 2020, 2050, 2100\n",
    "vmin, vmax = -5, 5\n",
    "\n",
    "y_ssp370.sel(time=yr0).tas.plot(ax=axes.flat[0],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "y_ssp370.sel(time=yr1).tas.plot(ax=axes.flat[1],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "y_ssp370.sel(time=yr2).tas.plot(ax=axes.flat[2],vmin=vmin,vmax=vmax,cmap='RdBu_r')\n",
    "\n",
    "fig.suptitle('future simulations (ssp370) for temperature',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471d9e1-38e9-4560-b75a-3c4ede306b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Neural Networks (NN) for temperature prediction\n",
    "\n",
    "\n",
    "Now, we are trying to use NN to predict the surface air temperature (tas), based on the time series of CO2 & CH4 emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b55ee-397d-4b77-9348-63cd758ddd47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. data preprocssing: prepare data for training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5319c-42ba-4c7b-acb1-c456eb6941fe",
   "metadata": {},
   "source": [
    "#### import data as training & test sets\n",
    "\n",
    "Here we train NN using simulations from 3 historical and 3 future scenarios. <br/> Then we test the trained NN using the ssp245 scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b8d82-0c79-4b9e-a837-f93dc8d5f888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_files    = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-aer\",\"hist-GHG\"]\n",
    "X_train_xr, _  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, _  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bada06-301f-4473-a450-7bf036483927",
   "metadata": {},
   "source": [
    "#### select relevant variables\n",
    "\n",
    "predictors: CO2 & CH4 <br/>\n",
    "predictand: tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02c1e3-9d35-45d6-9183-16f2327af69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "\n",
    "y_train_df = y_train_xr[\"tas\"].stack(stacked_dim=[\"latitude\", \"longitude\"])\n",
    "y_train_df = pd.DataFrame(y_train_df.to_pandas())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faad437-2bfe-45b9-aee9-ae011fa19135",
   "metadata": {},
   "source": [
    "This is how our predictors & predictand data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc644911-13ca-4308-bfc2-a4d9ade3af6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf91663-4133-460f-9b21-1b68499be07a",
   "metadata": {},
   "source": [
    "Note that here we stack the original 2-D tas data into a single dimension (for the purpose of NN implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d97dcd-a3d8-45f1-8755-a1b5deb78d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082bdb0-ffd1-47af-8655-d4e54e5bbc5f",
   "metadata": {},
   "source": [
    "#### Data normalization\n",
    "\n",
    "Let's normalize the input predictors by there mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd2e58-4153-4b04-bf56-3bbb3d9ee1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "\n",
    "#print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb9221-c18a-4d91-a66a-7903c54ac893",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Define the NN structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f00a4b-515c-41dc-82cb-ed5d1a6cd01e",
   "metadata": {},
   "source": [
    "Now the data preprocessing has been finished! Let's define our NN structure, which is shown in the below schematic.\n",
    "\n",
    "Here the NN we use has 3 hidden layers, and each hidden layer has 64 neurons. \n",
    "\n",
    "The NN input layer has 2 neurons, corresponding to CO2 & CH4 inputs respectively. \n",
    "\n",
    "The NN outputs are the global tas, each neuron of the output layer corresponds to each pixel. There are 13824 pixels in total (number of latitude: 96, number of longitude: 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55339419-2f0c-489c-934f-e08d070bbf24",
   "metadata": {},
   "source": [
    "![title](https://drive.google.com/uc?export=view&id=1wCIEX6GAN5h0_XOd23eUtdnkjpOJPpde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f158c5-b8e8-40f8-afa2-a167a2bd6f7e",
   "metadata": {},
   "source": [
    "Here are the hyperparameters for the NN training, such as the number of neurons per layer, learning rate, etc. Note that these hyperparameters here are for demonstration purposes only - they are not optimized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c789ea7-7c3c-444b-92db-4bcb3b43980b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "#n_neuron      \n",
    "#activation     \n",
    "#num_epochs     \n",
    "#learning_rate  \n",
    "#minibatch_size \n",
    "#model_num      \n",
    "#N_layers        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let us build a neural network from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9e5eb-2db7-4b13-ada2-5224b612878c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# To do --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4f99b-47b7-439b-877e-bfba672ef2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30152a4b-7e71-466e-89a3-990358c52831",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Train & save the NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e72c3-51f5-4f02-8f52-e13c17e3b747",
   "metadata": {},
   "source": [
    "Here we use `EarlyStopping` to avoid over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346683c-1495-4a53-9e60-69476fa1aa82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add early stopping\n",
    "\n",
    "#train and save NN history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8c31b-b2e6-46e6-a674-98ae3a69f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533761f-55bf-4503-a173-91f40100c427",
   "metadata": {},
   "source": [
    "we can save the trained model as the `.h5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f570f7c-fade-41a8-a6b2-41e2164e1154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO DO: save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e3382-5f0f-4962-ab5d-18980d175e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save(os.path.join(model_path,'NN_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d313e-f540-432c-b928-432f38817f45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Evaluate the trained model\n",
    "\n",
    "Now let's evaluate the trained NN on the test set, by comparing the NN predictions against the tas originally simulated under the ssp245 scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2038b4-476d-4059-8189-408fd15f202f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reload the saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16b202-c776-494b-84b8-0b10cfeff7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pre = model.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values, \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                       data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651455ff-c7db-4398-a78c-437658672bde",
   "metadata": {},
   "source": [
    "First we check whether the ML model can capture the spatial distribution of global temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d34543c-fca1-423f-8dbc-4e5b62d52218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9de418-89a8-49b2-bbb8-d84ad0513630",
   "metadata": {},
   "source": [
    "Then we also check whether the ML model can reproduce the time series of a given location.<br/> Here we take NYC as an example (40.7128° N, 74.0060° W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05beb3db-3e75-4003-a408-8ade9fcf72af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lat = 40.7128\n",
    "lon = -74.0060%360\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(9,4))\n",
    "y_test_xr.sel(latitude=lat,longitude=lon,method='nearest').tas.plot(marker='o',ax=ax,label='truth')\n",
    "y_test_pre.sel(latitude=lat,longitude=lon,method='nearest').tas.plot(marker='o',ax=ax,label='prediction')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('temperature (°C)')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbd654-37b6-4c01-b353-d66ab6ca3d83",
   "metadata": {},
   "source": [
    "Finally we check whether the ML model can capture the time series of global average temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fd05c-506c-4f9f-b31c-32a9e6876168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def global_mean_std_plot(X,label,color,ax,var='tas'):\n",
    "    weights  = np.cos(np.deg2rad(X.latitude))\n",
    "    tas_mean = X[var].weighted(weights).mean(['latitude', 'longitude']).data\n",
    "    tas_std  = X[var].weighted(weights).std(['latitude', 'longitude']).data\n",
    "    \n",
    "    x = X.time.data\n",
    "\n",
    "    ax.plot(x, tas_mean, label=label,color=color,linewidth=2)\n",
    "    ax.fill_between(x,tas_mean+tas_std,tas_mean-tas_std,facecolor=color,alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ceaac-3328-4f3a-817b-f7acc002a581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(9,4))\n",
    "\n",
    "global_mean_std_plot(y_test_xr,label='truth',ax=ax,color='tab:blue')\n",
    "global_mean_std_plot(y_test_pre,label='prediction',ax=ax,color='tab:orange')\n",
    "\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('global mean temperature (°C)')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda5f97-ee1a-4b88-96cb-febe45ab48cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa528c7-d160-4529-aa40-83ecd4c76b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c43ff-8094-4fdb-abc0-49d8c5d7af7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
